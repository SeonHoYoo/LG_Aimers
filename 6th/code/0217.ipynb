{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bec8ba5f-e9f7-447a-9bad-82179c05dae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_csv('train2.csv', encoding = 'cp949')\n",
    "test_data = pd.read_csv('test2.csv' , encoding = 'cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ce7afb8-b3f7-4a25-bffb-657bf9bb1ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.66186"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb30e23a-fd85-40a3-9747-03ab6a2afebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 45783, number of negative: 45782\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.031551 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 160\n",
      "[LightGBM] [Info] Number of data points in the train set: 91565, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500005 -> initscore=0.000022\n",
      "[LightGBM] [Info] Start training from score 0.000022\n",
      "Accuracy: 0.6636\n",
      "ROC-AUC: 0.7185\n",
      "Confusion Matrix:\n",
      " [[10498  9124]\n",
      " [ 4078 15543]]\n"
     ]
    }
   ],
   "source": [
    "############ 1 \n",
    "# 필요한 라이브러리 임포트\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\n",
    "import lightgbm as lgb  # LightGBM 모델\n",
    "\n",
    "# 1. 데이터 준비 및 전처리\n",
    "# 'train_data' DataFrame에서 ID, 시술 시기 코드, 시술 유형 칼럼을 제외한 나머지가 feature, \n",
    "# '임신 성공 여부'가 target입니다.\n",
    "\n",
    "# (1) 먼저 다운 샘플링을 위해 원본 DataFrame을 클래스별로 분리합니다.\n",
    "df_majority = train_data[train_data['임신 성공 여부'] == 0]\n",
    "df_minority = train_data[train_data['임신 성공 여부'] == 1]\n",
    "\n",
    "# (2) 다수 클래스(0)를 소수 클래스(1)의 수와 맞춰 다운 샘플링\n",
    "df_majority_downsampled = resample(\n",
    "    df_majority,\n",
    "    replace=False,                  # 중복 없이 샘플링\n",
    "    n_samples=len(df_minority),     # 소수 클래스와 동일한 수\n",
    "    random_state=42                 # 재현성을 위한 random_state 설정\n",
    ")\n",
    "\n",
    "# (3) 다운 샘플링된 데이터와 소수 클래스 데이터를 결합\n",
    "df_downsampled = pd.concat([df_majority_downsampled, df_minority])\n",
    "\n",
    "# 2. 피처와 타겟 변수 분리\n",
    "# 제외할 칼럼: 'ID', '시술 시기 코드', '시술 유형', 그리고 '임신 성공 여부'는 target이므로 제외\n",
    "cols_to_drop = ['ID', '시술 시기 코드', '시술 유형', '임신 성공 여부', 'ID', '시술 시기 코드', '시술 유형', '임신 성공 여부','여성 주 불임 원인', '부부 주 불임 원인', '부부 부 불임 원인', 'IVF 시술 횟수', 'IVF 출산 횟수', '혼합된 난자 수', '동결 배아 사용 여부', '신선 배아 사용 여부']\n",
    "X = df_downsampled.drop(columns=cols_to_drop)\n",
    "y = df_downsampled['임신 성공 여부']\n",
    "\n",
    "# 3. 학습/검증 데이터 분리 (Stratify 옵션으로 클래스 비율 유지)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 4. 모델 학습 (LightGBM 사용)\n",
    "clf = lgb.LGBMClassifier(random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# 5. 예측 및 평가\n",
    "y_pred = clf.predict(X_val)\n",
    "y_prob = clf.predict_proba(X_val)[:, 1]  # Positive class 확률\n",
    "\n",
    "# 평가 지표 출력\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "roc_auc = roc_auc_score(y_val, y_prob)\n",
    "conf_mat = confusion_matrix(y_val, y_pred)\n",
    "\n",
    "print(\"Accuracy: {:.4f}\".format(accuracy))\n",
    "print(\"ROC-AUC: {:.4f}\".format(roc_auc))\n",
    "print(\"Confusion Matrix:\\n\", conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "410fa374-8ff9-42ce-a07c-7285fab9651e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.55\n",
      "Accuracy: 0.6550\n",
      "ROC-AUC: 0.7185\n",
      "Confusion Matrix:\n",
      " [[12334  7288]\n",
      " [ 6251 13370]]\n",
      "F1 score : 0.7019\n",
      "--------------------------------------------------\n",
      "Threshold: 0.6\n",
      "Accuracy: 0.6416\n",
      "ROC-AUC: 0.7185\n",
      "Confusion Matrix:\n",
      " [[13848  5774]\n",
      " [ 8292 11329]]\n",
      "F1 score : 0.7019\n",
      "--------------------------------------------------\n",
      "Threshold: 0.65\n",
      "Accuracy: 0.6081\n",
      "ROC-AUC: 0.7185\n",
      "Confusion Matrix:\n",
      " [[15870  3752]\n",
      " [11626  7995]]\n",
      "F1 score : 0.7019\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 6. 다른 threshold 값에 따른 평가 지표 출력\n",
    "thresholds = [0.55, 0.6, 0.65]\n",
    "\n",
    "for thresh in thresholds:\n",
    "    # 해당 threshold 이상이면 1로 분류\n",
    "    y_pred_thresh = (y_prob >= thresh).astype(int)\n",
    "    \n",
    "    # 평가 지표 계산\n",
    "    acc = accuracy_score(y_val, y_pred_thresh)\n",
    "    roc_auc = roc_auc_score(y_val, y_prob)  # ROC-AUC는 확률값을 사용하므로 threshold와 무관\n",
    "    conf_mat = confusion_matrix(y_val, y_pred_thresh)\n",
    "    \n",
    "    print(f\"Threshold: {thresh}\")\n",
    "    print(\"Accuracy: {:.4f}\".format(acc))\n",
    "    print(\"ROC-AUC: {:.4f}\".format(roc_auc))\n",
    "    print(\"Confusion Matrix:\\n\", conf_mat)\n",
    "    print(\"F1 score : {:.4f}\".format(f1_score(y_val,y_pred)))\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff3fb0a7-4a62-4324-954d-0eaf54ddff1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7921614596605677"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score, f1_score\n",
    "recall = recall_score(y_val, y_pred)\n",
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63a79949-5da7-4959-bbdf-067f57fae1b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ID  임신 성공 여부 예측  임신 성공 여부 예측_확률\n",
      "0  TEST_00000            0        0.001347\n",
      "1  TEST_00001            0        0.000835\n",
      "2  TEST_00002            0        0.369695\n",
      "3  TEST_00003            0        0.270678\n",
      "4  TEST_00004            1        0.645813\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터 불러오기 (cp949 인코딩)\n",
    "test_data = pd.read_csv('test2.csv', encoding = 'cp949')\n",
    "\n",
    "# 테스트 데이터 전처리\n",
    "# 학습 시 사용했던 제외할 칼럼과 동일하게 제거합니다.\n",
    "cols_to_drop = ['ID', '시술 시기 코드', '시술 유형', '임신 성공 여부', 'ID', '시술 시기 코드', '시술 유형', '임신 성공 여부','여성 주 불임 원인', '부부 주 불임 원인', '부부 부 불임 원인', 'IVF 시술 횟수', 'IVF 출산 횟수', '혼합된 난자 수', '동결 배아 사용 여부', '신선 배아 사용 여부']\n",
    "X_test = test_data.drop(columns=cols_to_drop)\n",
    "\n",
    "# 예측 진행\n",
    "test_pred = clf.predict(X_test)\n",
    "test_prob = clf.predict_proba(X_test)[:, 1]  # 양성 클래스(1)에 대한 확률\n",
    "\n",
    "# 예측 결과를 테스트 데이터에 추가 (원하는 경우)\n",
    "test_data['임신 성공 여부 예측'] = test_pred\n",
    "test_data['임신 성공 여부 예측_확률'] = test_prob\n",
    "\n",
    "# 결과 확인\n",
    "print(test_data[['ID', '임신 성공 여부 예측', '임신 성공 여부 예측_확률']].head())\n",
    "\n",
    "# 예측 결과를 CSV 파일로 저장 (원하는 경우)\n",
    "test_data.to_csv('lgbm_test_ivf_columns_selection_predictions_0224.csv', index=False, encoding='cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1cc94009-c9b9-40e7-9d42-1849b6899ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 81 candidates, totalling 243 fits\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 45783, number of negative: 45782\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.056121 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 230\n",
      "[LightGBM] [Info] Number of data points in the train set: 91565, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500005 -> initscore=0.000022\n",
      "[LightGBM] [Info] Start training from score 0.000022\n",
      "Best Parameters:  {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 300, 'num_leaves': 50}\n",
      "Accuracy: 0.6629\n",
      "ROC-AUC: 0.7189\n",
      "Confusion Matrix:\n",
      " [[10508  9114]\n",
      " [ 4115 15506]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\n",
    "import lightgbm as lgb  # LightGBM 모델\n",
    "\n",
    "# 1. 데이터 준비 및 전처리\n",
    "# 'train_data' DataFrame에서 ID, 시술 시기 코드, 시술 유형 칼럼을 제외한 나머지가 feature, \n",
    "# '임신 성공 여부'가 target입니다.\n",
    "\n",
    "# (1) 먼저 다운 샘플링을 위해 원본 DataFrame을 클래스별로 분리합니다.\n",
    "df_majority = train_data[train_data['임신 성공 여부'] == 0]\n",
    "df_minority = train_data[train_data['임신 성공 여부'] == 1]\n",
    "\n",
    "# (2) 다수 클래스(0)를 소수 클래스(1)의 수와 맞춰 다운 샘플링\n",
    "df_majority_downsampled = resample(\n",
    "    df_majority,\n",
    "    replace=False,                  # 중복 없이 샘플링\n",
    "    n_samples=len(df_minority),     # 소수 클래스와 동일한 수\n",
    "    random_state=42                 # 재현성을 위한 random_state 설정\n",
    ")\n",
    "\n",
    "# (3) 다운 샘플링된 데이터와 소수 클래스 데이터를 결합\n",
    "df_downsampled = pd.concat([df_majority_downsampled, df_minority])\n",
    "\n",
    "# 2. 피처와 타겟 변수 분리\n",
    "# 제외할 칼럼: 'ID', '시술 시기 코드', '시술 유형', '임신 성공 여부'(target) 칼럼 제거\n",
    "cols_to_drop = ['ID', '시술 시기 코드', '시술 유형', '임신 성공 여부']\n",
    "X = df_downsampled.drop(columns=cols_to_drop)\n",
    "y = df_downsampled['임신 성공 여부']\n",
    "\n",
    "# 3. 학습/검증 데이터 분리 (Stratify 옵션으로 클래스 비율 유지)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 4. 하이퍼파라미터 튜닝: GridSearchCV를 사용하여 최적의 파라미터 탐색\n",
    "param_grid = {\n",
    "    'n_estimators': [300],\n",
    "    'learning_rate': [0.001, 0.01, 0.05],\n",
    "    'num_leaves': [50, 70],\n",
    "    'max_depth': [30]\n",
    "}\n",
    "\n",
    "lgb_estimator = lgb.LGBMClassifier(random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=lgb_estimator,\n",
    "    param_grid=param_grid,\n",
    "    scoring='accuracy',  # 또는 roc_auc 등 다른 평가지표 사용 가능\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters: \", grid_search.best_params_)\n",
    "\n",
    "# 5. 최적 모델로 검증 데이터 예측 및 평가\n",
    "best_clf = grid_search.best_estimator_\n",
    "\n",
    "y_pred = best_clf.predict(X_val)\n",
    "y_prob = best_clf.predict_proba(X_val)[:, 1]  # 양성 클래스(1)의 확률\n",
    "\n",
    "# 평가 지표 계산\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "roc_auc = roc_auc_score(y_val, y_prob)\n",
    "conf_mat = confusion_matrix(y_val, y_pred)\n",
    "\n",
    "print(\"Accuracy: {:.4f}\".format(accuracy))\n",
    "print(\"ROC-AUC: {:.4f}\".format(roc_auc))\n",
    "print(\"Confusion Matrix:\\n\", conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83e8c651-5a31-4499-88d4-80b6dc188055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 45783, number of negative: 45782\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017683 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 160\n",
      "[LightGBM] [Info] Number of data points in the train set: 91565, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500005 -> initscore=0.000022\n",
      "[LightGBM] [Info] Start training from score 0.000022\n",
      "Best Parameters:  {'learning_rate': 0.01, 'max_depth': 20, 'n_estimators': 500, 'num_leaves': 70}\n",
      "Accuracy: 0.6632\n",
      "ROC-AUC: 0.7182\n",
      "Confusion Matrix:\n",
      " [[10500  9122]\n",
      " [ 4095 15526]]\n"
     ]
    }
   ],
   "source": [
    "###############2\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\n",
    "import lightgbm as lgb  # LightGBM 모델\n",
    "\n",
    "# 1. 데이터 준비 및 전처리\n",
    "# 'train_data' DataFrame에서 ID, 시술 시기 코드, 시술 유형 칼럼을 제외한 나머지가 feature, \n",
    "# '임신 성공 여부'가 target입니다.\n",
    "\n",
    "# (1) 먼저 다운 샘플링을 위해 원본 DataFrame을 클래스별로 분리합니다.\n",
    "df_majority = train_data[train_data['임신 성공 여부'] == 0]\n",
    "df_minority = train_data[train_data['임신 성공 여부'] == 1]\n",
    "\n",
    "# (2) 다수 클래스(0)를 소수 클래스(1)의 수와 맞춰 다운 샘플링\n",
    "df_majority_downsampled = resample(\n",
    "    df_majority,\n",
    "    replace=False,                  # 중복 없이 샘플링\n",
    "    n_samples=len(df_minority),     # 소수 클래스와 동일한 수\n",
    "    random_state=42                 # 재현성을 위한 random_state 설정\n",
    ")\n",
    "\n",
    "# (3) 다운 샘플링된 데이터와 소수 클래스 데이터를 결합\n",
    "df_downsampled = pd.concat([df_majority_downsampled, df_minority])\n",
    "\n",
    "# 2. 피처와 타겟 변수 분리\n",
    "# 제외할 칼럼: 'ID', '시술 시기 코드', '시술 유형', '임신 성공 여부'(target) 칼럼 제거\n",
    "cols_to_drop = ['ID', '시술 시기 코드', '시술 유형', '임신 성공 여부', 'ID', '시술 시기 코드', '시술 유형', '임신 성공 여부','여성 주 불임 원인', '부부 주 불임 원인', '부부 부 불임 원인', 'IVF 시술 횟수', 'IVF 출산 횟수', '혼합된 난자 수', '동결 배아 사용 여부', '신선 배아 사용 여부']\n",
    "X = df_downsampled.drop(columns=cols_to_drop)\n",
    "y = df_downsampled['임신 성공 여부']\n",
    "\n",
    "# 3. 학습/검증 데이터 분리 (Stratify 옵션으로 클래스 비율 유지)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 4. 하이퍼파라미터 튜닝: GridSearchCV를 사용하여 최적의 파라미터 탐색\n",
    "param_grid = {\n",
    "    'n_estimators': [500],\n",
    "    'learning_rate': [0.01],\n",
    "    'num_leaves': [70],\n",
    "    'max_depth': [20]\n",
    "}\n",
    "\n",
    "lgb_estimator = lgb.LGBMClassifier(random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=lgb_estimator,\n",
    "    param_grid=param_grid,\n",
    "    scoring='accuracy',  # 또는 roc_auc 등 다른 평가지표 사용 가능\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters: \", grid_search.best_params_)\n",
    "\n",
    "# 5. 최적 모델로 검증 데이터 예측 및 평가\n",
    "best_clf = grid_search.best_estimator_\n",
    "\n",
    "y_pred = best_clf.predict(X_val)\n",
    "y_prob = best_clf.predict_proba(X_val)[:, 1]  # 양성 클래스(1)의 확률\n",
    "\n",
    "# 평가 지표 계산\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "roc_auc = roc_auc_score(y_val, y_prob)\n",
    "conf_mat = confusion_matrix(y_val, y_pred)\n",
    "\n",
    "print(\"Accuracy: {:.4f}\".format(accuracy))\n",
    "print(\"ROC-AUC: {:.4f}\".format(roc_auc))\n",
    "print(\"Confusion Matrix:\\n\", conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f218f676-3330-4962-8434-50f4e174db1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9230fd-0171-4fea-ad4b-29d84b5f185f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a549cc-867c-4ce9-9697-aa9d395ac7eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53005f83-e629-422b-b617-d2fa3d558947",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484eead1-dfe9-4f38-a654-3ffc67279372",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f059b8d2-ff05-4549-98b9-1ec4b9a254c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fd4f5b40-f2e0-4ac9-b4f8-ff371b438bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 81 candidates, totalling 243 fits\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 45783, number of negative: 45782\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007310 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 230\n",
      "[LightGBM] [Info] Number of data points in the train set: 91565, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500005 -> initscore=0.000022\n",
      "[LightGBM] [Info] Start training from score 0.000022\n",
      "Best Parameters:  {'learning_rate': 0.01, 'max_depth': -1, 'n_estimators': 300, 'num_leaves': 31}\n",
      "Accuracy: 0.6640\n",
      "ROC-AUC: 0.7191\n",
      "Confusion Matrix:\n",
      " [[10484  9138]\n",
      " [ 4047 15574]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\n",
    "import lightgbm as lgb  # LightGBM 모델\n",
    "\n",
    "# 1. 데이터 준비 및 전처리\n",
    "# 'train_data' DataFrame에서 ID, 시술 시기 코드, 시술 유형 칼럼을 제외한 나머지가 feature, \n",
    "# '임신 성공 여부'가 target입니다.\n",
    "\n",
    "# (1) 먼저 다운 샘플링을 위해 원본 DataFrame을 클래스별로 분리합니다.\n",
    "df_majority = train_data[train_data['임신 성공 여부'] == 0]\n",
    "df_minority = train_data[train_data['임신 성공 여부'] == 1]\n",
    "\n",
    "# (2) 다수 클래스(0)를 소수 클래스(1)의 수와 맞춰 다운 샘플링\n",
    "df_majority_downsampled = resample(\n",
    "    df_majority,\n",
    "    replace=False,                  # 중복 없이 샘플링\n",
    "    n_samples=len(df_minority),     # 소수 클래스와 동일한 수\n",
    "    random_state=42                 # 재현성을 위한 random_state 설정\n",
    ")\n",
    "\n",
    "# (3) 다운 샘플링된 데이터와 소수 클래스 데이터를 결합\n",
    "df_downsampled = pd.concat([df_majority_downsampled, df_minority])\n",
    "\n",
    "# 2. 피처와 타겟 변수 분리\n",
    "# 제외할 칼럼: 'ID', '시술 시기 코드', '시술 유형', '임신 성공 여부'(target) 칼럼 제거\n",
    "cols_to_drop = ['ID', '시술 시기 코드', '시술 유형', '임신 성공 여부']\n",
    "X = df_downsampled.drop(columns=cols_to_drop)\n",
    "y = df_downsampled['임신 성공 여부']\n",
    "\n",
    "# 3. 학습/검증 데이터 분리 (Stratify 옵션으로 클래스 비율 유지)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 4. 하이퍼파라미터 튜닝: GridSearchCV를 사용하여 최적의 파라미터 탐색\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'num_leaves': [31, 50, 70],\n",
    "    'max_depth': [-1, 10, 20]\n",
    "}\n",
    "\n",
    "lgb_estimator = lgb.LGBMClassifier(random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=lgb_estimator,\n",
    "    param_grid=param_grid,\n",
    "    scoring='roc_auc',  # 또는 roc_auc 등 다른 평가지표 사용 가능\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters: \", grid_search.best_params_)\n",
    "\n",
    "# 5. 최적 모델로 검증 데이터 예측 및 평가\n",
    "best_clf = grid_search.best_estimator_\n",
    "\n",
    "y_pred = best_clf.predict(X_val)\n",
    "y_prob = best_clf.predict_proba(X_val)[:, 1]  # 양성 클래스(1)의 확률\n",
    "\n",
    "# 평가 지표 계산\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "roc_auc = roc_auc_score(y_val, y_prob)\n",
    "conf_mat = confusion_matrix(y_val, y_pred)\n",
    "\n",
    "print(\"Accuracy: {:.4f}\".format(accuracy))\n",
    "print(\"ROC-AUC: {:.4f}\".format(roc_auc))\n",
    "print(\"Confusion Matrix:\\n\", conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c2d9de7e-76de-4454-ba8b-bc2d97caa251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ID  임신 성공 여부 예측  임신 성공 여부 예측_확률\n",
      "0  TEST_00000            0        0.001504\n",
      "1  TEST_00001            0        0.000689\n",
      "2  TEST_00002            0        0.383503\n",
      "3  TEST_00003            0        0.257484\n",
      "4  TEST_00004            1        0.648965\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터 불러오기 (cp949 인코딩)\n",
    "test_data = pd.read_csv('test2.csv', encoding = 'cp949')\n",
    "\n",
    "# 테스트 데이터 전처리\n",
    "# 학습 시 사용했던 제외할 칼럼과 동일하게 제거합니다.\n",
    "cols_to_drop = ['ID', '시술 시기 코드', '시술 유형', '임신 성공 여부']\n",
    "X_test = test_data.drop(columns=cols_to_drop)\n",
    "\n",
    "# 예측 진행\n",
    "test_pred = clf.predict(X_test)\n",
    "test_prob = clf.predict_proba(X_test)[:, 1]  # 양성 클래스(1)에 대한 확률\n",
    "\n",
    "# 예측 결과를 테스트 데이터에 추가 (원하는 경우)\n",
    "test_data['임신 성공 여부 예측'] = test_pred\n",
    "test_data['임신 성공 여부 예측_확률'] = test_prob\n",
    "\n",
    "# 결과 확인\n",
    "print(test_data[['ID', '임신 성공 여부 예측', '임신 성공 여부 예측_확률']].head())\n",
    "\n",
    "# 예측 결과를 CSV 파일로 저장 (원하는 경우)\n",
    "test_data.to_csv('test_ivf_lgbm_tuned_predictions.csv', index=False, encoding='cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66e4474-3bd5-478a-92d0-bc38c5fbd9f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
