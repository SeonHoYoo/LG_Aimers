{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c88bd60d-1ca0-4ff6-8a12-9ffc627cc30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_csv('train2.csv', encoding = 'cp949')\n",
    "test_data = pd.read_csv('test2.csv' , encoding = 'cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7159959-6fd6-4c9e-87c1-9169c8a4ac2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6193\n",
      "ROC-AUC: 0.6704\n",
      "Confusion Matrix:\n",
      " [[11205  8417]\n",
      " [ 6521 13100]]\n"
     ]
    }
   ],
   "source": [
    "# 필요한 라이브러리 임포트\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier  # RandomForest 모델\n",
    "\n",
    "# 1. 데이터 준비 및 전처리\n",
    "# 'train_data' DataFrame에서 ID, 시술 시기 코드, 시술 유형 칼럼 등을 제외한 나머지가 feature,\n",
    "# '임신 성공 여부'가 target입니다.\n",
    "\n",
    "# (1) 클래스별 데이터 분리 (다운 샘플링 전)\n",
    "df_majority = train_data[train_data['임신 성공 여부'] == 0]\n",
    "df_minority = train_data[train_data['임신 성공 여부'] == 1]\n",
    "\n",
    "# (2) 다수 클래스(0)를 소수 클래스(1)의 수와 맞춰 다운 샘플링\n",
    "df_majority_downsampled = resample(\n",
    "    df_majority,\n",
    "    replace=False,                  # 중복 없이 샘플링\n",
    "    n_samples=len(df_minority),     # 소수 클래스와 동일한 수\n",
    "    random_state=42                 # 재현성을 위한 random_state 설정\n",
    ")\n",
    "\n",
    "# (3) 다운 샘플링된 데이터와 소수 클래스 데이터를 결합\n",
    "df_downsampled = pd.concat([df_majority_downsampled, df_minority])\n",
    "\n",
    "# 2. 피처와 타겟 변수 분리\n",
    "# 제외할 칼럼: 'ID', '시술 시기 코드', '시술 유형', 그리고 '임신 성공 여부' (타겟 변수)\n",
    "cols_to_drop = ['ID', '시술 시기 코드', '시술 유형', '임신 성공 여부',\n",
    "                '여성 주 불임 원인', '부부 주 불임 원인', '부부 부 불임 원인',\n",
    "                'IVF 시술 횟수', 'IVF 출산 횟수', '혼합된 난자 수',\n",
    "                '동결 배아 사용 여부', '신선 배아 사용 여부']\n",
    "X = df_downsampled.drop(columns=cols_to_drop)\n",
    "y = df_downsampled['임신 성공 여부']\n",
    "\n",
    "# 3. 학습/검증 데이터 분리 (Stratify 옵션으로 클래스 비율 유지)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 4. 모델 학습 (RandomForest 사용)\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# 5. 예측 및 평가\n",
    "y_pred = clf.predict(X_val)\n",
    "y_prob = clf.predict_proba(X_val)[:, 1]  # Positive class 확률\n",
    "\n",
    "# 평가 지표 출력\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "roc_auc = roc_auc_score(y_val, y_prob)\n",
    "conf_mat = confusion_matrix(y_val, y_pred)\n",
    "\n",
    "print(\"Accuracy: {:.4f}\".format(accuracy))\n",
    "print(\"ROC-AUC: {:.4f}\".format(roc_auc))\n",
    "print(\"Confusion Matrix:\\n\", conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ae00815-2319-4371-9263-8d792c1b9949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.55\n",
      "Accuracy: 0.6105\n",
      "ROC-AUC: 0.6704\n",
      "Confusion Matrix:\n",
      " [[12467  7155]\n",
      " [ 8131 11490]]\n",
      "F1 score : 0.6369\n",
      "--------------------------------------------------\n",
      "Threshold: 0.6\n",
      "Accuracy: 0.6030\n",
      "ROC-AUC: 0.6704\n",
      "Confusion Matrix:\n",
      " [[13513  6109]\n",
      " [ 9470 10151]]\n",
      "F1 score : 0.6369\n",
      "--------------------------------------------------\n",
      "Threshold: 0.65\n",
      "Accuracy: 0.5884\n",
      "ROC-AUC: 0.6704\n",
      "Confusion Matrix:\n",
      " [[14572  5050]\n",
      " [11101  8520]]\n",
      "F1 score : 0.6369\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 6. 다른 threshold 값에 따른 평가 지표 출력\n",
    "from sklearn.metrics import f1_score\n",
    "thresholds = [0.55, 0.6, 0.65]\n",
    "\n",
    "for thresh in thresholds:\n",
    "    # 해당 threshold 이상이면 1로 분류\n",
    "    y_pred_thresh = (y_prob >= thresh).astype(int)\n",
    "    \n",
    "    # 평가 지표 계산\n",
    "    acc = accuracy_score(y_val, y_pred_thresh)\n",
    "    roc_auc = roc_auc_score(y_val, y_prob)  # ROC-AUC는 확률값을 사용하므로 threshold와 무관\n",
    "    conf_mat = confusion_matrix(y_val, y_pred_thresh)\n",
    "    \n",
    "    print(f\"Threshold: {thresh}\")\n",
    "    print(\"Accuracy: {:.4f}\".format(acc))\n",
    "    print(\"ROC-AUC: {:.4f}\".format(roc_auc))\n",
    "    print(\"Confusion Matrix:\\n\", conf_mat)\n",
    "    print(\"F1 score : {:.4f}\".format(f1_score(y_val,y_pred)))\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd30ae7e-76f6-43ee-8c6d-035ac31927d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "최적의 하이퍼파라미터: {'max_depth': 100, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 300}\n",
      "Accuracy: 0.6598\n",
      "ROC-AUC: 0.7125\n",
      "Confusion Matrix:\n",
      " [[10616  9006]\n",
      " [ 4344 15277]]\n"
     ]
    }
   ],
   "source": [
    "# 필요한 라이브러리 임포트\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# 1. 데이터 준비 및 전처리\n",
    "# 'train_data' DataFrame에서 ID, 시술 시기 코드, 시술 유형 칼럼 등을 제외한 나머지가 feature,\n",
    "# '임신 성공 여부'가 target입니다.\n",
    "\n",
    "# (1) 클래스별 데이터 분리 (다운 샘플링 전)\n",
    "df_majority = train_data[train_data['임신 성공 여부'] == 0]\n",
    "df_minority = train_data[train_data['임신 성공 여부'] == 1]\n",
    "\n",
    "# (2) 다수 클래스(0)를 소수 클래스(1)의 수와 맞춰 다운 샘플링\n",
    "df_majority_downsampled = resample(\n",
    "    df_majority,\n",
    "    replace=False,                  # 중복 없이 샘플링\n",
    "    n_samples=len(df_minority),     # 소수 클래스와 동일한 수\n",
    "    random_state=42                 # 재현성을 위한 random_state 설정\n",
    ")\n",
    "\n",
    "# (3) 다운 샘플링된 데이터와 소수 클래스 데이터를 결합\n",
    "df_downsampled = pd.concat([df_majority_downsampled, df_minority])\n",
    "\n",
    "# 2. 피처와 타겟 변수 분리\n",
    "# 제외할 칼럼: 'ID', '시술 시기 코드', '시술 유형', 그리고 '임신 성공 여부' (타겟 변수)\n",
    "cols_to_drop = ['ID', '시술 시기 코드', '시술 유형', '임신 성공 여부',\n",
    "                '여성 주 불임 원인', '부부 주 불임 원인', '부부 부 불임 원인',\n",
    "                'IVF 시술 횟수', 'IVF 출산 횟수', '혼합된 난자 수',\n",
    "                '동결 배아 사용 여부', '신선 배아 사용 여부']\n",
    "X = df_downsampled.drop(columns=cols_to_drop)\n",
    "y = df_downsampled['임신 성공 여부']\n",
    "\n",
    "# 3. 학습/검증 데이터 분리 (Stratify 옵션으로 클래스 비율 유지)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 4. 하이퍼파라미터 튜닝을 위한 그리드 서치 수행\n",
    "# AUC ROC를 최대화하는 방향으로 탐색합니다.\n",
    "param_grid = {\n",
    "    'n_estimators': [300],\n",
    "    'max_depth': [100],\n",
    "    'min_samples_split': [10],\n",
    "    'min_samples_leaf': [4]\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=param_grid,\n",
    "    scoring='roc_auc',  # AUC ROC 점수를 기준으로 최적 파라미터 탐색\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"최적의 하이퍼파라미터:\", grid_search.best_params_)\n",
    "\n",
    "# 5. 최적 모델로 예측 및 평가\n",
    "best_rf = grid_search.best_estimator_\n",
    "\n",
    "y_pred = best_rf.predict(X_val)\n",
    "y_prob = best_rf.predict_proba(X_val)[:, 1]  # Positive class 확률\n",
    "\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "roc_auc = roc_auc_score(y_val, y_prob)\n",
    "conf_mat = confusion_matrix(y_val, y_pred)\n",
    "\n",
    "print(\"Accuracy: {:.4f}\".format(accuracy))\n",
    "print(\"ROC-AUC: {:.4f}\".format(roc_auc))\n",
    "print(\"Confusion Matrix:\\n\", conf_mat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3ce020cc-fcf6-4829-8219-665b932b236a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "최적의 하이퍼파라미터: {'max_depth': 200, 'min_samples_leaf': 8, 'min_samples_split': 20, 'n_estimators': 500}\n",
      "Accuracy: 0.6626\n",
      "ROC-AUC: 0.7166\n",
      "Confusion Matrix:\n",
      " [[10598  9024]\n",
      " [ 4216 15405]]\n"
     ]
    }
   ],
   "source": [
    "###########3\n",
    "\n",
    "# 필요한 라이브러리 임포트\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# 1. 데이터 준비 및 전처리\n",
    "# 'train_data' DataFrame에서 ID, 시술 시기 코드, 시술 유형 칼럼 등을 제외한 나머지가 feature,\n",
    "# '임신 성공 여부'가 target입니다.\n",
    "\n",
    "# (1) 클래스별 데이터 분리 (다운 샘플링 전)\n",
    "df_majority = train_data[train_data['임신 성공 여부'] == 0]\n",
    "df_minority = train_data[train_data['임신 성공 여부'] == 1]\n",
    "\n",
    "# (2) 다수 클래스(0)를 소수 클래스(1)의 수와 맞춰 다운 샘플링\n",
    "df_majority_downsampled = resample(\n",
    "    df_majority,\n",
    "    replace=False,                  # 중복 없이 샘플링\n",
    "    n_samples=len(df_minority),     # 소수 클래스와 동일한 수\n",
    "    random_state=42                 # 재현성을 위한 random_state 설정\n",
    ")\n",
    "\n",
    "# (3) 다운 샘플링된 데이터와 소수 클래스 데이터를 결합\n",
    "df_downsampled = pd.concat([df_majority_downsampled, df_minority])\n",
    "\n",
    "# 2. 피처와 타겟 변수 분리\n",
    "# 제외할 칼럼: 'ID', '시술 시기 코드', '시술 유형', 그리고 '임신 성공 여부' (타겟 변수)\n",
    "cols_to_drop = ['ID', '시술 시기 코드', '시술 유형', '임신 성공 여부',\n",
    "                '여성 주 불임 원인', '부부 주 불임 원인', '부부 부 불임 원인',\n",
    "                'IVF 시술 횟수', 'IVF 출산 횟수', '혼합된 난자 수',\n",
    "                '동결 배아 사용 여부', '신선 배아 사용 여부']\n",
    "X = df_downsampled.drop(columns=cols_to_drop)\n",
    "y = df_downsampled['임신 성공 여부']\n",
    "\n",
    "# 3. 학습/검증 데이터 분리 (Stratify 옵션으로 클래스 비율 유지)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 4. 하이퍼파라미터 튜닝을 위한 그리드 서치 수행\n",
    "# AUC ROC를 최대화하는 방향으로 탐색합니다.\n",
    "param_grid = {\n",
    "    'n_estimators': [300, 500],\n",
    "    'max_depth': [200, 300],\n",
    "    'min_samples_split': [10, 20],\n",
    "    'min_samples_leaf': [4, 8]\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=param_grid,\n",
    "    scoring='roc_auc',  # AUC ROC 점수를 기준으로 최적 파라미터 탐색\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"최적의 하이퍼파라미터:\", grid_search.best_params_)\n",
    "\n",
    "# 5. 최적 모델로 예측 및 평가\n",
    "best_rf = grid_search.best_estimator_\n",
    "\n",
    "y_pred = best_rf.predict(X_val)\n",
    "y_prob = best_rf.predict_proba(X_val)[:, 1]  # Positive class 확률\n",
    "\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "roc_auc = roc_auc_score(y_val, y_prob)\n",
    "conf_mat = confusion_matrix(y_val, y_pred)\n",
    "\n",
    "print(\"Accuracy: {:.4f}\".format(accuracy))\n",
    "print(\"ROC-AUC: {:.4f}\".format(roc_auc))\n",
    "print(\"Confusion Matrix:\\n\", conf_mat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1620a61-3e9a-4e7c-bde7-5b116a27195c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bb1963-8d0c-4d34-9c19-5ec9ec78b0ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e5a34b-eaaf-41f5-ad8e-8e2fe6a22c5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b2a014-4337-4c03-a1b2-cdfb9cb141de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0bb162-f427-4d82-913f-92458d34f471",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ec2d89-1982-4701-96c8-ece249a029b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54aec549-5edc-4e15-ba0c-cef7751a6418",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0aa58a-fec1-4249-9b6a-e74824ac5217",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "267f550d-ec06-4e28-ae6b-164785001f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "RandomForest 최적의 하이퍼파라미터: {'max_depth': 200, 'min_samples_leaf': 8, 'min_samples_split': 20, 'n_estimators': 500}\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 45783, number of negative: 45782\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005948 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 160\n",
      "[LightGBM] [Info] Number of data points in the train set: 91565, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500005 -> initscore=0.000022\n",
      "[LightGBM] [Info] Start training from score 0.000022\n",
      "LightGBM (기본 모델) 최적의 하이퍼파라미터: {'learning_rate': 0.01, 'max_depth': -1, 'n_estimators': 300, 'num_leaves': 31}\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 45783, number of negative: 45782\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005288 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 160\n",
      "[LightGBM] [Info] Number of data points in the train set: 91565, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500005 -> initscore=0.000022\n",
      "[LightGBM] [Info] Start training from score 0.000022\n",
      "LightGBM (GridSearchCV) 최적의 하이퍼파라미터: {'learning_rate': 0.01, 'max_depth': 20, 'n_estimators': 500, 'num_leaves': 70}\n",
      "Ensemble Accuracy: 0.6634\n",
      "Ensemble ROC-AUC: 0.7186\n",
      "Ensemble Confusion Matrix:\n",
      " [[10522  9100]\n",
      " [ 4109 15512]]\n"
     ]
    }
   ],
   "source": [
    "# 필요한 라이브러리 임포트\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import lightgbm as lgb\n",
    "\n",
    "# 1. 데이터 준비 및 전처리\n",
    "df_majority = train_data[train_data['임신 성공 여부'] == 0]\n",
    "df_minority = train_data[train_data['임신 성공 여부'] == 1]\n",
    "\n",
    "# (1) 다수 클래스(0)를 소수 클래스(1)의 수와 맞춰 다운샘플링\n",
    "df_majority_downsampled = resample(\n",
    "    df_majority,\n",
    "    replace=False,\n",
    "    n_samples=len(df_minority),\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# (2) 다운샘플링된 다수 클래스와 소수 클래스를 결합\n",
    "df_downsampled = pd.concat([df_majority_downsampled, df_minority])\n",
    "\n",
    "# (3) 피처와 타겟 변수 분리\n",
    "cols_to_drop = ['ID', '시술 시기 코드', '시술 유형', '임신 성공 여부',\n",
    "                '여성 주 불임 원인', '부부 주 불임 원인', '부부 부 불임 원인',\n",
    "                'IVF 시술 횟수', 'IVF 출산 횟수', '혼합된 난자 수',\n",
    "                '동결 배아 사용 여부', '신선 배아 사용 여부']\n",
    "X = df_downsampled.drop(columns=cols_to_drop)\n",
    "y = df_downsampled['임신 성공 여부']\n",
    "\n",
    "# (4) 학습/검증 데이터 분리 (Stratify 옵션으로 클래스 비율 유지)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "####################################\n",
    "# Model 1: RandomForest (GridSearchCV 활용)\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [500],\n",
    "    'max_depth': [200, 300],\n",
    "    'min_samples_split': [20],\n",
    "    'min_samples_leaf': [8]\n",
    "}\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "grid_search_rf = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=param_grid_rf,\n",
    "    scoring='roc_auc',  # AUC ROC 기준 최적화\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "best_rf = grid_search_rf.best_estimator_\n",
    "print(\"RandomForest 최적의 하이퍼파라미터:\", grid_search_rf.best_params_)\n",
    "\n",
    "####################################\n",
    "# Model 2: LightGBM (기본 모델, GridSearchCV 활용)\n",
    "# 파라미터 값들을 리스트로 감싸줍니다.\n",
    "param_grid_lgb_2 = {\n",
    "    'learning_rate': [0.01],\n",
    "    'max_depth': [-1],\n",
    "    'n_estimators': [300],\n",
    "    'num_leaves': [31]\n",
    "}\n",
    "lgb_model_plain = lgb.LGBMClassifier(random_state=42)\n",
    "grid_lgb_model_plain = GridSearchCV(\n",
    "    estimator=lgb_model_plain,  # lgb_estimator가 아닌 lgb_model_plain 사용\n",
    "    param_grid=param_grid_lgb_2,\n",
    "    scoring='roc_auc',\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "grid_lgb_model_plain.fit(X_train, y_train)\n",
    "best_lgb_plain = grid_lgb_model_plain.best_estimator_\n",
    "print(\"LightGBM (기본 모델) 최적의 하이퍼파라미터:\", grid_lgb_model_plain.best_params_)\n",
    "\n",
    "####################################\n",
    "# Model 3: LightGBM (GridSearchCV 활용)\n",
    "param_grid_lgb = {\n",
    "    'n_estimators': [500],\n",
    "    'learning_rate': [0.01],\n",
    "    'num_leaves': [70],\n",
    "    'max_depth': [20]\n",
    "}\n",
    "lgb_estimator = lgb.LGBMClassifier(random_state=42)\n",
    "grid_search_lgb = GridSearchCV(\n",
    "    estimator=lgb_estimator,\n",
    "    param_grid=param_grid_lgb,\n",
    "    scoring='roc_auc',\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "grid_search_lgb.fit(X_train, y_train)\n",
    "best_lgb = grid_search_lgb.best_estimator_\n",
    "print(\"LightGBM (GridSearchCV) 최적의 하이퍼파라미터:\", grid_search_lgb.best_params_)\n",
    "\n",
    "####################################\n",
    "# Ensemble: 3개 모델의 예측 확률 평균 기반 보팅\n",
    "prob_rf = best_rf.predict_proba(X_val)[:, 1]\n",
    "prob_lgb_plain = best_lgb_plain.predict_proba(X_val)[:, 1]\n",
    "prob_lgb_best = best_lgb.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# 세 모델의 예측 확률 평균 계산\n",
    "ensemble_prob = (prob_rf + prob_lgb_plain + prob_lgb_best) / 3\n",
    "\n",
    "# 평균 확률이 0.5 이상이면 1, 미만이면 0으로 최종 예측\n",
    "ensemble_pred = (ensemble_prob >= 0.5).astype(int)\n",
    "\n",
    "# 평가 지표 계산\n",
    "ensemble_accuracy = accuracy_score(y_val, ensemble_pred)\n",
    "ensemble_roc_auc = roc_auc_score(y_val, ensemble_prob)\n",
    "ensemble_conf_mat = confusion_matrix(y_val, ensemble_pred)\n",
    "\n",
    "print(\"Ensemble Accuracy: {:.4f}\".format(ensemble_accuracy))\n",
    "print(\"Ensemble ROC-AUC: {:.4f}\".format(ensemble_roc_auc))\n",
    "print(\"Ensemble Confusion Matrix:\\n\", ensemble_conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b06a97a1-c774-45ad-bed0-583cd4069c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ID  임신 성공 여부 예측  임신 성공 여부 예측_확률\n",
      "0  TEST_00000            0        0.017405\n",
      "1  TEST_00001            0        0.017568\n",
      "2  TEST_00002            0        0.382444\n",
      "3  TEST_00003            0        0.255156\n",
      "4  TEST_00004            1        0.644357\n"
     ]
    }
   ],
   "source": [
    "####################################\n",
    "# 2. 테스트 데이터 예측\n",
    "# 테스트 데이터 불러오기 (cp949 인코딩)\n",
    "test_data = pd.read_csv('test2.csv', encoding='cp949')\n",
    "\n",
    "# 테스트 데이터 전처리: 학습 시 사용했던 제외할 칼럼과 동일하게 제거\n",
    "cols_to_drop_test = ['ID', '시술 시기 코드', '시술 유형', '임신 성공 여부',\n",
    "                '여성 주 불임 원인', '부부 주 불임 원인', '부부 부 불임 원인',\n",
    "                'IVF 시술 횟수', 'IVF 출산 횟수', '혼합된 난자 수',\n",
    "                '동결 배아 사용 여부', '신선 배아 사용 여부']\n",
    "X_test = test_data.drop(columns=cols_to_drop_test)\n",
    "\n",
    "# 각 모델에 대한 예측 확률 계산\n",
    "test_prob_rf = best_rf.predict_proba(X_test)[:, 1]\n",
    "test_prob_lgb_plain = best_lgb_plain.predict_proba(X_test)[:, 1]\n",
    "test_prob_lgb_best = best_lgb.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# 세 모델의 예측 확률 평균 계산 (Ensemble)\n",
    "ensemble_test_prob = (test_prob_rf + test_prob_lgb_plain + test_prob_lgb_best) / 3\n",
    "ensemble_test_pred = (ensemble_test_prob >= 0.5).astype(int)\n",
    "\n",
    "# 예측 결과를 테스트 데이터에 추가\n",
    "test_data['임신 성공 여부 예측'] = ensemble_test_pred\n",
    "test_data['임신 성공 여부 예측_확률'] = ensemble_test_prob\n",
    "\n",
    "# 결과 확인\n",
    "print(test_data[['ID', '임신 성공 여부 예측', '임신 성공 여부 예측_확률']].head())\n",
    "\n",
    "# 예측 결과를 CSV 파일로 저장\n",
    "test_data.to_csv('test_ivf_ensemble_predictions_0225.csv', index=False, encoding='cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e26f50-21e9-453d-a7a1-7bfec71291e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
